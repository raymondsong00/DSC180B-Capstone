{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meant to test the eval_script notebook and be used to develop new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_script import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/home/llm-hackathon/LLaVA/raymond/022624_test_answers.jsonl'\n",
    "train_path = '/home/llm-hackathon/LLaVA/raymond/022624patient_finding_impression.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inference_path = test_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inference_radiologist_answers_path = '../raymond/022924_test_patient_finding_impression_answers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inference, train_df = read_and_process(test_inference_path, train_data_path, test_inference_radiologist_answers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llm-hackathon/enter/envs/datalite_env/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00846447, -0.05173079,  0.01183672, ...,  0.04621582,\n",
       "         -0.04155276, -0.01782972],\n",
       "        [ 0.01473015, -0.01546272,  0.00398262, ..., -0.00700474,\n",
       "         -0.00466846, -0.00929033],\n",
       "        [-0.03427599,  0.01181116, -0.00187504, ...,  0.01684257,\n",
       "         -0.04247951, -0.03929309],\n",
       "        ...,\n",
       "        [ 0.00286386, -0.03022714,  0.03308079, ...,  0.00189669,\n",
       "         -0.00960621, -0.02583438],\n",
       "        [-0.00933187, -0.01008405, -0.01296106, ...,  0.01904776,\n",
       "         -0.02439373, -0.0150676 ],\n",
       "        [-0.00710746,  0.04919457, -0.02325286, ...,  0.02464723,\n",
       "         -0.06983981, -0.00430589]], dtype=float32),\n",
       " array([[-0.00372339, -0.04481244,  0.01672847, ...,  0.02248272,\n",
       "         -0.01003785, -0.0324695 ],\n",
       "        [ 0.00405076, -0.02084093,  0.00442956, ..., -0.01587569,\n",
       "          0.00672667, -0.01146238],\n",
       "        [ 0.01158176, -0.01551827,  0.01685445, ...,  0.02394384,\n",
       "         -0.01284015, -0.01170298],\n",
       "        ...,\n",
       "        [ 0.01676421, -0.04147111,  0.01988393, ..., -0.01945909,\n",
       "         -0.04421889, -0.0258592 ],\n",
       "        [ 0.02139846, -0.04542099, -0.00431716, ...,  0.00086777,\n",
       "         -0.0253091 , -0.02984143],\n",
       "        [-0.0238866 , -0.05089358, -0.03325853, ..., -0.01400523,\n",
       "         -0.02579693, -0.01456957]], dtype=float32),\n",
       " array([0.8058597 , 0.9447984 , 0.6379664 , ..., 0.76527727, 0.7768879 ,\n",
       "        0.49210933], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "get_sim_scores(test_inference['llava_report'], test_inference['radiologist_report'], sent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalite_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
